{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' D_NAMES: This is a list containing names of various Arabic diacritics. Each\n",
    " element of the list represents a specific diacritic type. '''\n",
    "D_NAMES = ['Fathatan', 'Dammatan', 'Kasratan', 'Fatha', 'Damma', 'Kasra', 'Shadda', 'Sukun']\n",
    "\n",
    "##############################################################################################\n",
    "\n",
    "''' NAME2DIACRITIC: This uses a dictionary comprehension to create a mapping \n",
    "from diacritic names to their corresponding Unicode characters.'''\n",
    "NAME2DIACRITIC = dict((name, chr(code)) for name, code in zip(D_NAMES, range(0x064B, 0x0653)))\n",
    "\n",
    "##############################################################################################\n",
    "\n",
    "''' DIACRITIC2NAME: This is the inverse of the previous dictionary.'''\n",
    "DIACRITIC2NAME = dict((code, name) for name, code in NAME2DIACRITIC.items())\n",
    "\n",
    "##############################################################################################\n",
    "\n",
    "''' ARABIC_DIACRITICS: This creates a frozenset containing the Unicode\n",
    " characters of all the diacritics.'''\n",
    "ARABIC_DIACRITICS = frozenset(NAME2DIACRITIC.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract The Arabic Words From The Text and neglect the un-needed characters, words and numbers.  \n",
    "def extract_arabic_words(text):\n",
    "    arabic_pattern = re.compile('[\\u0600-\\u06FF]+')\n",
    "    arabic_matches = arabic_pattern.findall(text)\n",
    "    result = ' '.join(arabic_matches)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace {؛, ،, .} with <\\s> and append <s> after each replacement\n",
    "def preprocess_text(text):\n",
    "    processed_text = re.sub(r'[؛،\\.]+', '</s><s>', text)\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return the diacritics from the text while keeping their original positions.\n",
    "def extract_diacritics(text):\n",
    "    assert isinstance(text, str)\n",
    "    diacritics = []\n",
    "    for i in range(1, len(text)):\n",
    "        if text[i] in ARABIC_DIACRITICS:\n",
    "            if text[i-1] == NAME2DIACRITIC['Shadda']:\n",
    "                diacritics[-1] = (text[i-1], text[i])\n",
    "            else:\n",
    "                diacritics.append(text[i])\n",
    "        elif text[i - 1] not in ARABIC_DIACRITICS:\n",
    "            diacritics.append('')\n",
    "    if text[-1] not in ARABIC_DIACRITICS:\n",
    "        diacritics.append('')\n",
    "    return diacritics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all standard diacritics from the text, leaving the letters only.\n",
    "def clear_diacritics(text):\n",
    "    assert isinstance(text, str)\n",
    "    return ''.join([l for l in text if l not in ARABIC_DIACRITICS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Byte Pair Encoding\n",
    "\n",
    "def get_stats(vocab): # Get the frequency of each pair of characters in the vocabulary\n",
    "    pairs = Counter()\n",
    "    # Loop over the words in the vocabulary\n",
    "    for word, freq in vocab.items():\n",
    "        symbols = word.split()\n",
    "        for i in range(len(symbols) - 1):\n",
    "            pairs[symbols[i], symbols[i + 1]] += freq\n",
    "    return pairs\n",
    "\n",
    "def merge_vocab(pair, vocab): # Merge the most frequent pair of characters in the vocabulary\n",
    "    new_vocab = {}\n",
    "    # Convert the pair of words into a single word\n",
    "    bigram = ' '.join(pair)\n",
    "    replacement = ''.join(pair)\n",
    "    # Loop over the words in the vocabulary\n",
    "    for word in vocab:\n",
    "        # Replace the most frequent pair of characters with the new merged word\n",
    "        new_word = word.replace(bigram, replacement)\n",
    "        new_vocab[new_word] = vocab[word]\n",
    "    \n",
    "    # Return the new vocabulary\n",
    "    return new_vocab\n",
    "\n",
    "def byte_pair_encoding(text, num_merges): # Apply the Byte Pair Encoding algorithm\n",
    "    # Tokenize the text into Arabic words\n",
    "    vocab = Counter(text.split())\n",
    "\n",
    "    # loop for the number of merges\n",
    "    for i in range(num_merges):\n",
    "        pairs = get_stats(vocab)\n",
    "        # Break if there are no more pairs to merge\n",
    "        if not pairs:\n",
    "            break\n",
    "        # Merge the most frequent pair of characters in the vocabulary\n",
    "        best_pair = max(pairs, key=pairs.get)\n",
    "        vocab = merge_vocab(best_pair, vocab)\n",
    "\n",
    "    # Convert the final vocabulary into a list of tokens (Arabic words)\n",
    "    tokens = list(vocab.keys())\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example \n",
    "Here we just try (extract_arabic_words) to a sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample data to see the results\n",
    "sample_Data = '''قَوْلُهُ : ( أَوْ قَطَعَ الْأَوَّلُ يَدَهُ إلَخْ ) قَالَ الزَّرْكَشِيُّ( 14 / 123 )\n",
    "ابْنُ عَرَفَةَ : قَوْلُهُ : بِلَفْظٍ يَقْتَضِيه كَإِنْكَارِ غَيْرِ حَدِيثٍ بِالْإِسْلَامِ وُجُوبَ مَا عُلِمَ وُجُوبُهُ مِنْ الدِّينِ ضَرُورَةً ( كَإِلْقَاءِ مُصْحَفٍ بِقَذَرٍ وَشَدِّ زُنَّارٍ ) ابْنُ عَرَفَةَ : قَوْلُ ابْنِ شَاسٍ : أَوْ بِفِعْلٍ يَتَضَمَّنُهُ هُوَ كَلُبْسِ الزُّنَّارِ وَإِلْقَاءِ الْمُصْحَفِ فِي صَرِيحِ النَّجَاسَةِ وَالسُّجُودِ لِلصَّنَمِ وَنَحْوِ ذَلِكَ ( وَسِحْرٍ ) مُحَمَّدٌ : قَوْلُ مَالِكٍ وَأَصْحَابِهِ أَنَّ السَّاحِرَ كَافِرٌ بِاَللَّهِ تَعَالَى قَالَ مَالِكٌ : هُوَ كَالزِّنْدِيقِ إذَا عَمِلَ السِّحْرَ بِنَفْسِهِ قُتِلَ وَلَمْ يُسْتَتَبْ .\n",
    "( قَوْلُهُ لِعَدَمِ مَا تَتَعَلَّقُ إلَخْ ) أَيْ الْوَصِيَّةُ ( قَوْلُهُ مَا مَرَّ ) أَيْ قُبَيْلَ قَوْلِ الْمَتْنِ لَغَتْ وَلَوْ اقْتَصَرَ عَلَى أَوْصَيْت لَهُ بِشَاةٍ أَوْ أَعْطُوهُ شَاةً وَلَا غَنَمَ لَهُ عِنْدَ الْمَوْتِ هَلْ تَبْطُلُ الْوَصِيَّةُ أَوْ يُشْتَرَى لَهُ شَاةٌ وَيُؤْخَذُ مِنْ قَوْلِهِ الْآتِي كَمَا لَوْ لَمْ يَقُلْ مِنْ مَالِي وَلَا مِنْ غَنَمِي أَنَّهَا لَا تَبْطُلُ ، وَعِبَارَةُ الْكَنْزِ وَلَوْ لَمْ يَقُلْ مِنْ مَالِي وَلَا مِنْ غَنَمِي لَمْ يَتَعَيَّنْ غَنَمُهُ إنْ كَانَتْ انْتَهَتْ ا ه سم ( قَوْلُهُ فَيُعْطَى وَاحِدَةً مِنْهَا إلَخْ ) كَمَا لَوْ كَانَتْ مَوْجُودَةً عِنْدَ الْوَصِيَّةِ وَالْمَوْتِ ، وَلَا يَجُوزُ أَنْ يُعْطَى وَاحِدَةً مِنْ غَيْرِ غَنَمِهِ فِي الصُّورَتَيْنِ وَإِنْ تَرَاضَيَا ؛ لِأَنَّهُ صُلْحٌ عَلَى مَجْهُولٍ مُغْنِي وَنِهَايَةٌ قَالَ ع ش قَوْلُهُ وَاحِدَةً مِنْهَا أَيْ كَامِلَةً ، وَلَا يَجُوزُ أَنْ يُعْطَى نِصْفَيْنِ مِنْ شَاتَيْنِ ؛ لِأَنَّهُ لَا يُسَمَّى شَاةً وَقَوْلُهُ وَلَا يَجُوزُ أَنْ يُعْطَى وَاحِدَةً مِنْ غَيْرِ غَنَمِهِ وَيَنْبَغِي أَنْ يُقَالَ مِثْلُ ذَلِكَ فِي الْأَرِقَّاءِ ا ه .'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Arabic words\n",
    "arabic_words = extract_arabic_words(sample_Data)\n",
    "\n",
    "# Specify the output file path\n",
    "output_file_path = \"filterd_output.txt\"\n",
    "\n",
    "# Write the Arabic words to the output file\n",
    "with open(output_file_path, \"w\", encoding=\"utf-8\") as output_file:\n",
    "    output_file.write(arabic_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process The Training Data\n",
    "using our four functions we will read the 'train.txt' to extract just Arabic words and process these words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from input file\n",
    "input_file_path = \"../train.txt\"  # Replace with your input file path\n",
    "with open(input_file_path, \"r\", encoding=\"utf-8\") as input_file:\n",
    "    input_text = input_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\24 4a\\1\\24\\NLP\\project\\code\\Machine-generation-of-Arabic-diacritical-marks\\preprocessing\\preprocess.ipynb Cell 15\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/24%204a/1/24/NLP/project/code/Machine-generation-of-Arabic-diacritical-marks/preprocessing/preprocess.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Extract Arabic words\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/24%204a/1/24/NLP/project/code/Machine-generation-of-Arabic-diacritical-marks/preprocessing/preprocess.ipynb#X20sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m arabic_words \u001b[39m=\u001b[39m extract_arabic_words(input_text)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/24%204a/1/24/NLP/project/code/Machine-generation-of-Arabic-diacritical-marks/preprocessing/preprocess.ipynb#X20sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Specify the output file path\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/24%204a/1/24/NLP/project/code/Machine-generation-of-Arabic-diacritical-marks/preprocessing/preprocess.ipynb#X20sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m output_file_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mfiltered_output.txt\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'input_text' is not defined"
     ]
    }
   ],
   "source": [
    "# Extract Arabic words\n",
    "arabic_words = extract_arabic_words(input_text)\n",
    "\n",
    "# Specify the output file path\n",
    "output_file_path = \"filtered_output.txt\"\n",
    "\n",
    "# Write the Arabic words to the output file\n",
    "with open(output_file_path, \"w\", encoding=\"utf-8\") as output_file:\n",
    "    output_file.write(arabic_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from input file\n",
    "path_filtered = \"./filtered_output.txt\"  # Replace with your input file path\n",
    "with open(path_filtered, \"r\", encoding=\"utf-8\") as input_file:\n",
    "    input_read = input_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed text has been written to processed_output.txt\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the text\n",
    "processed_text = preprocess_text(input_read)\n",
    "\n",
    "# Write the preprocessed text to the output file\n",
    "output_file_path = \"processed_output.txt\"\n",
    "\n",
    "with open(output_file_path, \"w\", encoding=\"utf-8\") as output_file:\n",
    "    output_file.write(processed_text)\n",
    "\n",
    "print(f\"Preprocessed text has been written to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output diacritics written to diacritics2.txt\n"
     ]
    }
   ],
   "source": [
    "# Open and read the input text file\n",
    "input_file_path = 'processed_output.txt'  # Change this to the path of your input file\n",
    "with open(input_file_path, 'r', encoding='utf-8') as file:\n",
    "    input_text = file.read()\n",
    "\n",
    "# Call the extract_diacritics function\n",
    "output_diacritics = extract_diacritics(input_text)\n",
    "\n",
    "# Write the output to a new text file\n",
    "output_file_path = 'diacritics2.txt'  # Change this to the path of your output file\n",
    "with open(output_file_path, 'w', encoding='utf-8') as file:\n",
    "    for diacritic in output_diacritics:\n",
    "        if isinstance(diacritic, tuple):\n",
    "            file.write(''.join(diacritic) + ' ')\n",
    "        else:\n",
    "            file.write(diacritic + ' ')\n",
    "\n",
    "print(f\"Output diacritics written to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output words written to words.txt\n"
     ]
    }
   ],
   "source": [
    "# Open and read the input text file\n",
    "input_file_path = 'processed_output.txt'  # Change this to the path of your input file\n",
    "with open(input_file_path, 'r', encoding='utf-8') as file:\n",
    "    input_text = file.read()\n",
    "\n",
    "# Call the clear_diacritics function\n",
    "output_words = clear_diacritics(input_text)\n",
    "\n",
    "# Write the output to a new text file\n",
    "output_file_path = 'words.txt'  # Change this to the path of your output file\n",
    "with open(output_file_path, 'w', encoding='utf-8') as file:\n",
    "    for words in output_words:\n",
    "        if isinstance(words, tuple):\n",
    "            file.write(''.join(words))\n",
    "        else:\n",
    "            file.write(words)\n",
    "\n",
    "print(f\"Output words written to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output words_with_separators written to words_with_separators.txt\n"
     ]
    }
   ],
   "source": [
    "# Open and read the input text file\n",
    "input_file_path = 'filtered_output.txt'  # Change this to the path of your input file\n",
    "with open(input_file_path, 'r', encoding='utf-8') as file:\n",
    "    input_text = file.read()\n",
    "\n",
    "# Call the clear_diacritics function\n",
    "output_words = clear_diacritics(input_text)\n",
    "\n",
    "# Write the output to a new text file\n",
    "output_file_path = 'words_with_separators.txt'  # Change this to the path of your output file\n",
    "with open(output_file_path, 'w', encoding='utf-8') as file:\n",
    "    for words in output_words:\n",
    "        if isinstance(words, tuple):\n",
    "            file.write(''.join(words))\n",
    "        else:\n",
    "            file.write(words)\n",
    "\n",
    "print(f\"Output words_with_separators written to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output tokens written to tokens.txt\n"
     ]
    }
   ],
   "source": [
    "# Open and read the input text file\n",
    "input_file_path = 'filtered_output.txt'  # Change this to the path of your input file\n",
    "with open(input_file_path, 'r', encoding='utf-8') as file:\n",
    "    input_text = file.read()\n",
    "\n",
    "tokens = byte_pair_encoding(input_text, 10000000)\n",
    "\n",
    "# Write the output to a new text file\n",
    "output_file_path = 'tokens.txt'  \n",
    "with open(output_file_path, 'w', encoding='utf-8') as file:\n",
    "    for token in tokens:\n",
    "        file.write(token + '\\n')\n",
    "\n",
    "print(f\"Output tokens written to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
