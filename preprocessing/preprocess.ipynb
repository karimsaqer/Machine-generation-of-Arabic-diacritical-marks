{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated D_NAMES with 15 labels\n",
    "D_NAMES = ['Fatha', 'Fathatan', 'Damma', 'Dammatan', 'Kasra', 'Kasratan', 'Sukun', 'Shadda', 'Shadda with Fatha',\n",
    "           'Shadda with Fathatan', 'Shadda with Damma', 'Shadda with Dammatan', 'Shadda with Kasra', 'Shadda with Kasratan', 'Empty']\n",
    "\n",
    "##############################################################################################\n",
    "\n",
    "# Updated NAME2DIACRITIC with 15 labels\n",
    "NAME2DIACRITIC = dict((name, chr(code)) for name, code in zip(D_NAMES, range(0x064B, 0x0661)))\n",
    "\n",
    "##############################################################################################\n",
    "\n",
    "# Updated DIACRITIC2NAME with 15 labels\n",
    "DIACRITIC2NAME = dict((code, name) for name, code in NAME2DIACRITIC.items())\n",
    "\n",
    "##############################################################################################\n",
    "\n",
    "# ARABIC_DIACRITICS remains the same as it includes the Unicode characters of all the diacritics\n",
    "ARABIC_DIACRITICS = frozenset(NAME2DIACRITIC.values())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract The Arabic Words From The Text and neglect the un-needed characters, words and numbers.  \n",
    "def extract_arabic_words(text):\n",
    "    arabic_pattern = re.compile('[\\u0600-\\u06FF]+')\n",
    "    arabic_matches = arabic_pattern.findall(text)\n",
    "    result = ' '.join(arabic_matches)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace {؛, ،, .} with <\\s> and append <s> after each replacement\n",
    "def preprocess_text(text):\n",
    "    processed_text = re.sub(r'[؛،\\.]+', '</s><s>', text)\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return the diacritics from the text while keeping their original positions.\n",
    "def extract_diacritics(text):\n",
    "    assert isinstance(text, str)\n",
    "    diacritics = []\n",
    "    for i in range(1, len(text)):\n",
    "        if text[i] in ARABIC_DIACRITICS:\n",
    "            if text[i-1] == NAME2DIACRITIC['Shadda']:\n",
    "                # Use the updated D_NAMES index for Shadda combinations\n",
    "                diacritics[-1] = (DIACRITIC2NAME.get(text[i-1], 'Empty'), DIACRITIC2NAME.get(text[i], 'Empty'))\n",
    "            else:\n",
    "                # Use the updated D_NAMES index for other diacritics\n",
    "                diacritics.append(DIACRITIC2NAME.get(text[i], 'Empty'))\n",
    "        elif text[i - 1] not in ARABIC_DIACRITICS:\n",
    "            # Write 'Empty' for characters without diacritics\n",
    "            diacritics.append('Empty')\n",
    "    if text[-1] not in ARABIC_DIACRITICS:\n",
    "        # Write 'Empty' for the last character without diacritics\n",
    "        diacritics.append('Empty')\n",
    "    return diacritics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_diacritics_to_indices(input_file_path, output_file_path):\n",
    "    # Read the diacritics from the text file\n",
    "    with open(input_file_path, 'r', encoding='utf-8') as file:\n",
    "        diacritics_text = file.read().strip()\n",
    "\n",
    "    # D_NAMES mapping\n",
    "    D_NAMES = ['Fatha', 'Fathatan', 'Damma', 'Dammatan', 'Kasra', 'Kasratan', 'Sukun', 'Shadda', 'Shadda with Fatha',\n",
    "               'Shadda with Fathatan', 'Shadda with Damma', 'Shadda with Dammatan', 'Shadda with Kasra', 'Shadda with Kasratan', 'Empty']\n",
    "\n",
    "    # Map diacritics to their corresponding indices in D_NAMES\n",
    "    diacritics_indices = [D_NAMES.index(diacritic) for diacritic in diacritics_text.split()]\n",
    "\n",
    "    # Write the indices to the output file\n",
    "    with open(output_file_path, 'w', encoding='utf-8') as file:\n",
    "        file.write(\" \".join(map(str, diacritics_indices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all standard diacritics from the text, leaving the letters only.\n",
    "def clear_diacritics(text):\n",
    "    assert isinstance(text, str)\n",
    "    return ''.join([l for l in text if l not in ARABIC_DIACRITICS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Byte Pair Encoding\n",
    "\n",
    "def get_stats(vocab): # Get the frequency of each pair of characters in the vocabulary\n",
    "    pairs = Counter()\n",
    "    # Loop over the words in the vocabulary\n",
    "    for word, freq in vocab.items():\n",
    "        symbols = word.split()\n",
    "        for i in range(len(symbols) - 1):\n",
    "            pairs[symbols[i], symbols[i + 1]] += freq\n",
    "    return pairs\n",
    "\n",
    "def merge_vocab(pair, vocab): # Merge the most frequent pair of characters in the vocabulary\n",
    "    new_vocab = {}\n",
    "    # Convert the pair of words into a single word\n",
    "    bigram = ' '.join(pair)\n",
    "    replacement = ''.join(pair)\n",
    "    # Loop over the words in the vocabulary\n",
    "    for word in vocab:\n",
    "        # Replace the most frequent pair of characters with the new merged word\n",
    "        new_word = word.replace(bigram, replacement)\n",
    "        new_vocab[new_word] = vocab[word]\n",
    "    \n",
    "    # Return the new vocabulary\n",
    "    return new_vocab\n",
    "\n",
    "def byte_pair_encoding(text, num_merges): # Apply the Byte Pair Encoding algorithm\n",
    "    # Tokenize the text into Arabic words\n",
    "    vocab = Counter(text.split())\n",
    "\n",
    "    # loop for the number of merges\n",
    "    for i in range(num_merges):\n",
    "        pairs = get_stats(vocab)\n",
    "        # Break if there are no more pairs to merge\n",
    "        if not pairs:\n",
    "            break\n",
    "        # Merge the most frequent pair of characters in the vocabulary\n",
    "        best_pair = max(pairs, key=pairs.get)\n",
    "        vocab = merge_vocab(best_pair, vocab)\n",
    "\n",
    "    # Convert the final vocabulary into a list of tokens (Arabic words)\n",
    "    tokens = list(vocab.keys())\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example \n",
    "Here we just try (extract_arabic_words) to a sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample data to see the results\n",
    "sample_Data = '''قَوْلُهُ : ( أَوْ قَطَعَ الْأَوَّلُ يَدَهُ إلَخْ ) قَالَ الزَّرْكَشِيُّ( 14 / 123 )\n",
    "ابْنُ عَرَفَةَ : قَوْلُهُ : بِلَفْظٍ يَقْتَضِيه كَإِنْكَارِ غَيْرِ حَدِيثٍ بِالْإِسْلَامِ وُجُوبَ مَا عُلِمَ وُجُوبُهُ مِنْ الدِّينِ ضَرُورَةً ( كَإِلْقَاءِ مُصْحَفٍ بِقَذَرٍ وَشَدِّ زُنَّارٍ ) ابْنُ عَرَفَةَ : قَوْلُ ابْنِ شَاسٍ : أَوْ بِفِعْلٍ يَتَضَمَّنُهُ هُوَ كَلُبْسِ الزُّنَّارِ وَإِلْقَاءِ الْمُصْحَفِ فِي صَرِيحِ النَّجَاسَةِ وَالسُّجُودِ لِلصَّنَمِ وَنَحْوِ ذَلِكَ ( وَسِحْرٍ ) مُحَمَّدٌ : قَوْلُ مَالِكٍ وَأَصْحَابِهِ أَنَّ السَّاحِرَ كَافِرٌ بِاَللَّهِ تَعَالَى قَالَ مَالِكٌ : هُوَ كَالزِّنْدِيقِ إذَا عَمِلَ السِّحْرَ بِنَفْسِهِ قُتِلَ وَلَمْ يُسْتَتَبْ .\n",
    "( قَوْلُهُ لِعَدَمِ مَا تَتَعَلَّقُ إلَخْ ) أَيْ الْوَصِيَّةُ ( قَوْلُهُ مَا مَرَّ ) أَيْ قُبَيْلَ قَوْلِ الْمَتْنِ لَغَتْ وَلَوْ اقْتَصَرَ عَلَى أَوْصَيْت لَهُ بِشَاةٍ أَوْ أَعْطُوهُ شَاةً وَلَا غَنَمَ لَهُ عِنْدَ الْمَوْتِ هَلْ تَبْطُلُ الْوَصِيَّةُ أَوْ يُشْتَرَى لَهُ شَاةٌ وَيُؤْخَذُ مِنْ قَوْلِهِ الْآتِي كَمَا لَوْ لَمْ يَقُلْ مِنْ مَالِي وَلَا مِنْ غَنَمِي أَنَّهَا لَا تَبْطُلُ ، وَعِبَارَةُ الْكَنْزِ وَلَوْ لَمْ يَقُلْ مِنْ مَالِي وَلَا مِنْ غَنَمِي لَمْ يَتَعَيَّنْ غَنَمُهُ إنْ كَانَتْ انْتَهَتْ ا ه سم ( قَوْلُهُ فَيُعْطَى وَاحِدَةً مِنْهَا إلَخْ ) كَمَا لَوْ كَانَتْ مَوْجُودَةً عِنْدَ الْوَصِيَّةِ وَالْمَوْتِ ، وَلَا يَجُوزُ أَنْ يُعْطَى وَاحِدَةً مِنْ غَيْرِ غَنَمِهِ فِي الصُّورَتَيْنِ وَإِنْ تَرَاضَيَا ؛ لِأَنَّهُ صُلْحٌ عَلَى مَجْهُولٍ مُغْنِي وَنِهَايَةٌ قَالَ ع ش قَوْلُهُ وَاحِدَةً مِنْهَا أَيْ كَامِلَةً ، وَلَا يَجُوزُ أَنْ يُعْطَى نِصْفَيْنِ مِنْ شَاتَيْنِ ؛ لِأَنَّهُ لَا يُسَمَّى شَاةً وَقَوْلُهُ وَلَا يَجُوزُ أَنْ يُعْطَى وَاحِدَةً مِنْ غَيْرِ غَنَمِهِ وَيَنْبَغِي أَنْ يُقَالَ مِثْلُ ذَلِكَ فِي الْأَرِقَّاءِ ا ه .'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Arabic words\n",
    "arabic_words = extract_arabic_words(sample_Data)\n",
    "\n",
    "# Specify the output file path\n",
    "output_file_path = \"filterd_output.txt\"\n",
    "\n",
    "# Write the Arabic words to the output file\n",
    "with open(output_file_path, \"w\", encoding=\"utf-8\") as output_file:\n",
    "    output_file.write(arabic_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process The Training Data\n",
    "using our four functions we will read the 'train.txt' to extract just Arabic words and process these words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from input file\n",
    "input_file_path = \"../train.txt\"  # Replace with your input file path\n",
    "with open(input_file_path, \"r\", encoding=\"utf-8\") as input_file:\n",
    "    input_text = input_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Arabic words\n",
    "arabic_words = extract_arabic_words(input_text)\n",
    "\n",
    "# Specify the output file path\n",
    "output_file_path = \"filtered_output.txt\"\n",
    "\n",
    "# Write the Arabic words to the output file\n",
    "with open(output_file_path, \"w\", encoding=\"utf-8\") as output_file:\n",
    "    output_file.write(arabic_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from input file\n",
    "path_filtered = \"./filtered_output.txt\"  # Replace with your input file path\n",
    "with open(path_filtered, \"r\", encoding=\"utf-8\") as input_file:\n",
    "    input_read = input_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed text has been written to processed_output.txt\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the text\n",
    "processed_text = preprocess_text(input_read)\n",
    "\n",
    "# Write the preprocessed text to the output file\n",
    "output_file_path = \"processed_output.txt\"\n",
    "\n",
    "with open(output_file_path, \"w\", encoding=\"utf-8\") as output_file:\n",
    "    output_file.write(processed_text)\n",
    "\n",
    "print(f\"Preprocessed text has been written to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output diacritics written to diacritics2.txt\n"
     ]
    }
   ],
   "source": [
    "# Open and read the input text file\n",
    "input_file_path = 'processed_output.txt'  # Change this to the path of your input file\n",
    "with open(input_file_path, 'r', encoding='utf-8') as file:\n",
    "    input_text = file.read()\n",
    "\n",
    "# Call the extract_diacritics function\n",
    "output_diacritics = extract_diacritics(input_text)\n",
    "\n",
    "# Write the output to a new text file\n",
    "output_file_path = 'diacritics2.txt'  # Change this to the path of your output file\n",
    "with open(output_file_path, 'w', encoding='utf-8') as file:\n",
    "    for diacritic in output_diacritics:\n",
    "        if isinstance(diacritic, tuple):\n",
    "            file.write(''.join(diacritic) + ' ')\n",
    "        else:\n",
    "            file.write(diacritic + ' ')\n",
    "\n",
    "print(f\"Output diacritics written to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output words written to words.txt\n"
     ]
    }
   ],
   "source": [
    "# Open and read the input text file\n",
    "input_file_path = 'processed_output.txt'  # Change this to the path of your input file\n",
    "with open(input_file_path, 'r', encoding='utf-8') as file:\n",
    "    input_text = file.read()\n",
    "\n",
    "# Call the clear_diacritics function\n",
    "output_words = clear_diacritics(input_text)\n",
    "\n",
    "# Write the output to a new text file\n",
    "output_file_path = 'words.txt'  # Change this to the path of your output file\n",
    "with open(output_file_path, 'w', encoding='utf-8') as file:\n",
    "    for words in output_words:\n",
    "        if isinstance(words, tuple):\n",
    "            file.write(''.join(words))\n",
    "        else:\n",
    "            file.write(words)\n",
    "\n",
    "print(f\"Output words written to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output words_with_separators written to words_with_separators.txt\n"
     ]
    }
   ],
   "source": [
    "# Open and read the input text file\n",
    "input_file_path = 'filtered_output.txt'  # Change this to the path of your input file\n",
    "with open(input_file_path, 'r', encoding='utf-8') as file:\n",
    "    input_text = file.read()\n",
    "\n",
    "# Call the clear_diacritics function\n",
    "output_words = clear_diacritics(input_text)\n",
    "\n",
    "# Write the output to a new text file\n",
    "output_file_path = 'words_with_separators.txt'  # Change this to the path of your output file\n",
    "with open(output_file_path, 'w', encoding='utf-8') as file:\n",
    "    for words in output_words:\n",
    "        if isinstance(words, tuple):\n",
    "            file.write(''.join(words))\n",
    "        else:\n",
    "            file.write(words)\n",
    "\n",
    "print(f\"Output words_with_separators written to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output tokens written to tokens.txt\n"
     ]
    }
   ],
   "source": [
    "# Open and read the input text file\n",
    "input_file_path = 'filtered_output.txt'  # Change this to the path of your input file\n",
    "with open(input_file_path, 'r', encoding='utf-8') as file:\n",
    "    input_text = file.read()\n",
    "\n",
    "tokens = byte_pair_encoding(input_text, 10000000)\n",
    "\n",
    "# Write the output to a new text file\n",
    "output_file_path = 'tokens.txt'  \n",
    "with open(output_file_path, 'w', encoding='utf-8') as file:\n",
    "    for token in tokens:\n",
    "        file.write(token + '\\n')\n",
    "\n",
    "print(f\"Output tokens written to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from input file\n",
    "input_file_path = \"processed_output.txt\"  # Replace with your input file path\n",
    "with open(input_file_path, \"r\", encoding=\"utf-8\") as input_file:\n",
    "    input_text = input_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = input_text.split('</s><s>')\n",
    "\n",
    "# Write the sentences to the output file\n",
    "output_file_path = \"sentences.txt\"\n",
    "with open(output_file_path, \"w\", encoding=\"utf-8\") as output_file:\n",
    "    for sentence in sentences:\n",
    "        output_file.write(sentence + '\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output sentences_without_diacritics written to sentences_without_diacritics.txt\n"
     ]
    }
   ],
   "source": [
    "# Open and read the input text file\n",
    "input_file_path = 'sentences.txt'  # Change this to the path of your input file\n",
    "with open(input_file_path, 'r', encoding='utf-8') as file:\n",
    "    input_text = file.read()\n",
    "\n",
    "# Call the clear_diacritics function\n",
    "output_words = clear_diacritics(input_text)\n",
    "\n",
    "# Write the output to a new text file\n",
    "output_file_path = 'sentences_without_diacritics.txt'  # Change this to the path of your output file\n",
    "with open(output_file_path, 'w', encoding='utf-8') as file:\n",
    "    for words in output_words:\n",
    "        if isinstance(words, tuple):\n",
    "            file.write(''.join(words))\n",
    "        else:\n",
    "            file.write(words)\n",
    "\n",
    "print(f\"Output sentences_without_diacritics written to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output diacritics written to sentences_diacritics.txt\n"
     ]
    }
   ],
   "source": [
    "# Open and read the input text file\n",
    "input_file_path = 'sentences.txt'  # Change this to the path of your input file\n",
    "with open(input_file_path, 'r', encoding='utf-8') as file:\n",
    "    input_text = file.read()\n",
    "\n",
    "# Call the extract_diacritics function\n",
    "output_diacritics = extract_diacritics(input_text)\n",
    "\n",
    "# Write the output to a new text file\n",
    "output_file_path = 'sentences_diacritics.txt'  # Change this to the path of your output file\n",
    "with open(output_file_path, 'w', encoding='utf-8') as file:\n",
    "    for diacritic in output_diacritics:\n",
    "        if isinstance(diacritic, tuple):\n",
    "            file.write(''.join(diacritic) + ' ')\n",
    "        else:\n",
    "            file.write(diacritic + ' ')\n",
    "\n",
    "print(f\"Output diacritics written to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_path = 'sentences_diacritics.txt'\n",
    "output_file_path = 'sentences_diacritics_indexes.txt'\n",
    "map_diacritics_to_indices(input_file_path, output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output diacritics written to tokens_diacritics.txt\n"
     ]
    }
   ],
   "source": [
    "# Open and read the input text file\n",
    "input_file_path = 'tokens.txt'  # Change this to the path of your input file\n",
    "with open(input_file_path, 'r', encoding='utf-8') as file:\n",
    "    input_text = file.read()\n",
    "\n",
    "# Call the extract_diacritics function\n",
    "output_diacritics = extract_diacritics(input_text)\n",
    "\n",
    "# Write the output to a new text file\n",
    "output_file_path = 'tokens_diacritics.txt'  # Change this to the path of your output file\n",
    "with open(output_file_path, 'w', encoding='utf-8') as file:\n",
    "    for diacritic in output_diacritics:\n",
    "        if isinstance(diacritic, tuple):\n",
    "            file.write(''.join(diacritic) + ' ')\n",
    "        else:\n",
    "            file.write(diacritic + ' ')\n",
    "\n",
    "print(f\"Output diacritics written to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_path = 'tokens_diacritics.txt'\n",
    "output_file_path = 'tokens_diacritics_indexes.txt'\n",
    "map_diacritics_to_indices(input_file_path, output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
